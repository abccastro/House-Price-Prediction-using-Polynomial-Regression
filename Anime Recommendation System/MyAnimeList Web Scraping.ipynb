{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MyAnimeList Web Scraping Tool\n",
    "\n",
    "The purpose of this program is to extract data related to anime from MyAnimeList. This data includes details like the anime's title, genre, and rating, along with reviews and scores provided by members of the platform. The anime list that the program uses as its source is taken from the <a href=\"https://myanimelist.net/topanime.php\">\"Top Anime\"</a> section of MyAnimeList.\n",
    "\n",
    "**Note**: There is limitation to this program, and it will stop if an error is encountered after making the maximum allowed attempts to connect to MyAnimeList. To reduce the likelihood of errors, web scraping delays have been implemented. It is possible to extend the duration of the delay by modifying the **\"getSecondsDelay(page_num)\"** function. Alternatively, using proxies could potentially resolve this issue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import csv\n",
    "import time\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definition of functions for saving file, web scraping anime info and reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANIME_INFO_FILENAME = \"AnimeInfo.csv\"\n",
    "ANIME_REVIEWS_FILENAME = \"AnimeReviews.csv\"\n",
    "\n",
    "\n",
    "def saveAnimeInfo(anime_info_list, filename):\n",
    "    \"\"\"\n",
    "    The function that saved the anime information/reviews in a file\n",
    "    :param: list anime_info_list: List of anime information/reviews\n",
    "    :param str filemame: Name of the file\n",
    "    \"\"\"\n",
    "    \n",
    "    filepath = \"./Dataset/\" + filename\n",
    "    try:\n",
    "        with open(filepath, 'a', newline='', encoding=\"utf-16\") as csvfile:\n",
    "\n",
    "            fieldnames = list(anime_info_list[0].keys())\n",
    "            writer = csv.DictWriter(csvfile, delimiter=\",\", lineterminator=\"\\n\", fieldnames=fieldnames, quoting=csv.QUOTE_NONNUMERIC)\n",
    "\n",
    "            if csvfile.tell() == 0:\n",
    "                writer.writeheader()\n",
    "\n",
    "            for anime_info in anime_info_list:\n",
    "                writer.writerow(anime_info)\n",
    "\n",
    "            print(f\"Saved {len(anime_info_list)} records\")\n",
    "                \n",
    "    except Exception as err:\n",
    "        print(f\"Error saving the file: {err}\")\n",
    "\n",
    "\n",
    "def getSecondsDelay(page_num):\n",
    "    \"\"\"\n",
    "    The function that generates random time in seconds that is used to add delay to the execution of the program\n",
    "    :param page: Page number\n",
    "    :return str seconds: Random time in seconds\n",
    "    \"\"\"\n",
    "\n",
    "    return random.randint(0, 10) + (page_num % 10)\n",
    "\n",
    "\n",
    "def sanitizeAnimeInfo(field_name, info):\n",
    "    \"\"\"\n",
    "    The function that removes any extraneous details or characters from the data extracted by the scraping process\n",
    "    :param str field_name: Name of the field/feature\n",
    "    :info str info: Web scraped information\n",
    "    :return str info: Filtered information\n",
    "    \"\"\"\n",
    "    \n",
    "    if field_name in ['genres', 'themes', 'demographic']:\n",
    "        info_split = set(re.split('\\W+', info))\n",
    "        info = \", \".join(info_split)\n",
    "\n",
    "    if field_name in ['producers', 'licensors']:\n",
    "        info = info.replace(\"|,|\", \", \")\n",
    "\n",
    "    if field_name in ['ranked', 'popularity']:\n",
    "        info = info[1:]\n",
    "\n",
    "    if field_name in ['ranked', 'score']:\n",
    "        info = info[:info.find(\"|\")]\n",
    "    \n",
    "    if 'None found' in info:\n",
    "        info = ''\n",
    "\n",
    "    return info\n",
    "\n",
    "\n",
    "def scrapeAnimeInfo(url):\n",
    "    \"\"\"\n",
    "    The function that web scraped anime information and stats from MyAnimeList\n",
    "    :param str url: Link of the anime page\n",
    "    :return dict anime_info: Key-value pair containing anime information and stats\n",
    "    \"\"\"\n",
    "\n",
    "    # Web scrape anime info on the left panel\n",
    "    anime_info_key = ('anime_id', 'title', 'synonyms', 'japanese', 'english', 'type', 'episodes', 'status', 'aired', 'premiered', 'producers', \n",
    "                      'licensors', 'studios', 'source', 'genres', 'themes', 'demographic', 'duration', 'rating', 'score', \n",
    "                      'ranked', 'popularity', 'members', 'favorites')\n",
    "    anime_info = dict.fromkeys(anime_info_key, \"\")    \n",
    "\n",
    "    page = requests.get(url + \"/stats\")\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "    \n",
    "    anime_info['anime_id'] = soup.find(\"input\", { \"type\" : \"hidden\", \"name\" : \"aid\" })['value']\n",
    "    anime_info['title'] = soup.find(\"h1\", class_=\"title-name\").get_text(strip=True)\n",
    "\n",
    "    print(f\"- {anime_info['title']}\")\n",
    "    \n",
    "    left_panel = soup.find(\"div\", class_=\"leftside\")\n",
    "    left_info = left_panel.find_all(\"div\", class_=\"spaceit_pad\")\n",
    "\n",
    "    for elem in left_info:\n",
    "        info = elem.get_text(\"|\", strip=True)\n",
    "        delimeter = info.find(\"|\")\n",
    "\n",
    "        if delimeter != -1:\n",
    "            # Separate field name from info\n",
    "            field_name = info[:(delimeter-1)].lower()\n",
    "            info = info[(delimeter+1):]\n",
    "\n",
    "            if field_name not in anime_info_key:\n",
    "                continue\n",
    "\n",
    "            info = sanitizeAnimeInfo(field_name, info)\n",
    "\n",
    "            anime_info[field_name] = info\n",
    "\n",
    "    # Web scape anime stats on right panel\n",
    "    anime_stats_key = ('watching', 'completed', 'on-hold', 'dropped', 'plan_to_watch')\n",
    "    anime_stats = dict.fromkeys(anime_stats_key, \"\") \n",
    "\n",
    "    right_panel = soup.find(\"div\", class_=\"rightside\")\n",
    "    right_stats = right_panel.find_all(\"div\", class_=\"spaceit_pad\")\n",
    "\n",
    "    for elem in right_stats:\n",
    "        info = elem.get_text(\"|\", strip=True)\n",
    "        delimeter = info.find(\"|\")\n",
    "\n",
    "        if delimeter != -1:\n",
    "            # Separate field name from info\n",
    "            field_name = info[:(delimeter-1)].replace(\" \", \"_\").lower()\n",
    "            info = info[(delimeter+1):]\n",
    "\n",
    "            if field_name == 'total':\n",
    "                break\n",
    "            else:\n",
    "                anime_stats[field_name] = info\n",
    "    \n",
    "    anime_info.update(anime_stats)\n",
    "    \n",
    "    return anime_info\n",
    "\n",
    "\n",
    "def scrapeAnimeReviews(anime_id, url):\n",
    "    \"\"\"\n",
    "    The function that web scraped anime reviews from MyAnimeList\n",
    "    :param int anime_id: Anime ID\n",
    "    :param str url: Link of the anime page\n",
    "    \"\"\"\n",
    "\n",
    "    page_num = 1\n",
    "    has_more_reviews = True\n",
    "\n",
    "    while has_more_reviews:\n",
    "        anime_reviews_list = []\n",
    "\n",
    "        url = url + \"/*/reviews?sort=suggested&filter_check=&filter_hide=&preliminary=on&spoiler=off&p=\" + str(page_num)\n",
    "        page = requests.get(url)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        reviews = soup.find_all(\"div\", class_=\"review-element\")\n",
    "        for elem in reviews:\n",
    "            anime_review = {}\n",
    "            anime_review['anime_id'] = anime_id\n",
    "            anime_review['username'] = elem.find(\"div\", \"username\").get_text(strip=True)\n",
    "            \n",
    "            rating = elem.find(\"div\", \"rating\").get_text(strip=True)\n",
    "            anime_review['rating'] = rating[(rating.find(\":\")+1):]    \n",
    "            anime_review['review'] = elem.find(\"div\", \"text\").get_text(strip=True)\n",
    "        \n",
    "            anime_reviews_list.append(anime_review)\n",
    "\n",
    "        print(f\"Page No.: {page_num} - {len(anime_reviews_list)} reviews\")\n",
    "        \n",
    "        if len(anime_reviews_list) != 0:\n",
    "            \n",
    "            saveAnimeInfo(anime_reviews_list, ANIME_REVIEWS_FILENAME)\n",
    "\n",
    "            prev_next_page = soup.find(\"div\", class_=\"ml4 mb8\").get_text(strip=True)\n",
    "            \n",
    "            if 'More Reviews' not in prev_next_page:\n",
    "                has_more_reviews = False\n",
    "            else:\n",
    "                page_num = page_num + 1\n",
    "        else:\n",
    "            has_more_reviews = False\n",
    "\n",
    "    \n",
    "        time.sleep(getSecondsDelay(page_num))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform web scraping to extract anime information. The list is based from the Top Anime from <a href=\"https://myanimelist.net/\">MyAnimeList</a> page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Pagination Number: 0\n",
      "- Shingeki no Kyojin: The Final Season - Kanketsu-hen\n",
      "Saved 1 records\n"
     ]
    }
   ],
   "source": [
    "HTTP_RESPONSE_OK = 200\n",
    "status_code = HTTP_RESPONSE_OK\n",
    "\n",
    "# NOTE: In case the program encounters an error and stops, this field can be modified to a pagination value \n",
    "# where the error occurred, allowing the process to resume. The pagination number can be determined by referring \n",
    "# to the logs provided below. \n",
    "page_num = 0 \n",
    "\n",
    "while status_code == HTTP_RESPONSE_OK:\n",
    "    anime_info_list = []\n",
    "\n",
    "    print(f\"\\nPagination Number: {page_num}\")\n",
    "\n",
    "    url = 'https://myanimelist.net/topanime.php?limit=' + str(page_num)\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "    anime_url_list = soup.find_all(\"h3\", class_=\"hoverinfo_trigger fl-l fs14 fw-b anime_ranking_h3\")\n",
    "\n",
    "    for elem in anime_url_list:\n",
    "        anime_url = elem.find(\"a\").get(\"href\")\n",
    "        anime_info = scrapeAnimeInfo(anime_url)\n",
    "        anime_info_list.append(anime_info)\n",
    "\n",
    "        time.sleep(getSecondsDelay(page_num))\n",
    "        \n",
    "    page_num = page_num + 50\n",
    "    status_code = page.status_code\n",
    "\n",
    "    saveAnimeInfo(anime_info_list, ANIME_INFO_FILENAME)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the anime information dataset created earlier. The IDs contained within it will be utilized to acquire anime reviews. This retrieval process has been separated from the retrieval of anime information because MyAnimeList generates errors if the maximum number of connections is exceeded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>title</th>\n",
       "      <th>synonyms</th>\n",
       "      <th>japanese</th>\n",
       "      <th>english</th>\n",
       "      <th>type</th>\n",
       "      <th>episodes</th>\n",
       "      <th>status</th>\n",
       "      <th>aired</th>\n",
       "      <th>premiered</th>\n",
       "      <th>...</th>\n",
       "      <th>score</th>\n",
       "      <th>ranked</th>\n",
       "      <th>popularity</th>\n",
       "      <th>members</th>\n",
       "      <th>favorites</th>\n",
       "      <th>watching</th>\n",
       "      <th>completed</th>\n",
       "      <th>on-hold</th>\n",
       "      <th>dropped</th>\n",
       "      <th>plan_to_watch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51535</td>\n",
       "      <td>Shingeki no Kyojin: The Final Season - Kankets...</td>\n",
       "      <td>Shingeki no Kyojin: The Final Season Part 3, S...</td>\n",
       "      <td>進撃の巨人 The Final Season完結編</td>\n",
       "      <td>Attack on Titan: Final Season - The Final Chap...</td>\n",
       "      <td>Special</td>\n",
       "      <td>2</td>\n",
       "      <td>Currently Airing</td>\n",
       "      <td>Mar 4, 2023 to 2023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.13</td>\n",
       "      <td>1</td>\n",
       "      <td>568</td>\n",
       "      <td>368525</td>\n",
       "      <td>7288</td>\n",
       "      <td>175801</td>\n",
       "      <td>345</td>\n",
       "      <td>15277</td>\n",
       "      <td>823</td>\n",
       "      <td>176279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id                                              title  \\\n",
       "0     51535  Shingeki no Kyojin: The Final Season - Kankets...   \n",
       "\n",
       "                                            synonyms  \\\n",
       "0  Shingeki no Kyojin: The Final Season Part 3, S...   \n",
       "\n",
       "                    japanese  \\\n",
       "0  進撃の巨人 The Final Season完結編   \n",
       "\n",
       "                                             english     type  episodes  \\\n",
       "0  Attack on Titan: Final Season - The Final Chap...  Special         2   \n",
       "\n",
       "             status                aired  premiered  ... score  ranked  \\\n",
       "0  Currently Airing  Mar 4, 2023 to 2023        NaN  ...  9.13       1   \n",
       "\n",
       "  popularity members favorites watching completed on-hold dropped  \\\n",
       "0        568  368525      7288   175801       345   15277     823   \n",
       "\n",
       "   plan_to_watch  \n",
       "0         176279  \n",
       "\n",
       "[1 rows x 29 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./Dataset/\" + ANIME_INFO_FILENAME\n",
    "anime_info_df = pd.read_csv(filepath, encoding='utf-16', thousands=\",\")\n",
    "anime_info_df.head(5)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform web scraping to extract user reviews and the corresponding scores for each anime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0. Shingeki no Kyojin: The Final Season - Kanketsu-hen (51535)\n",
      "Page No.: 1 - 20 reviews\n",
      "Saved 20 records\n",
      "Page No.: 2 - 20 reviews\n",
      "Saved 20 records\n",
      "Page No.: 3 - 17 reviews\n",
      "Saved 17 records\n",
      "\n",
      "1. Shingeki no Kyojin: The Final Season - Kanketsu-hen (51535)\n",
      "Page No.: 1 - 20 reviews\n",
      "Saved 20 records\n",
      "Page No.: 2 - 20 reviews\n",
      "Saved 20 records\n",
      "Page No.: 3 - 17 reviews\n",
      "Saved 17 records\n"
     ]
    }
   ],
   "source": [
    "url_base = \"https://myanimelist.net/anime/\"\n",
    "\n",
    "# NOTE: In case the program encounters an error and stops, this field can be modified to anime index where the error \n",
    "# occurred, allowing the process to resume. The index can be determined by referring to the logs provided below.\n",
    "# Before re-running the program, check first the file and remove all reviews related to anime that has failed. \n",
    "anime_idx_start = 0\n",
    "\n",
    "anime_df = anime_info_df[['anime_id', 'title']]\n",
    "anime_df = anime_df.loc[anime_idx_start:,]\n",
    "\n",
    "for idx, anime_id in enumerate(np.array(anime_df['anime_id'])):\n",
    "    anime_title = np.array(anime_df['title'])[idx]\n",
    "    anime_idx = np.array(anime_df.index)[idx]\n",
    "\n",
    "    print(f\"\\n{anime_idx}. {anime_title} ({anime_id})\")\n",
    "    \n",
    "    url_full = url_base + str(anime_id)\n",
    "    scrapeAnimeReviews(anime_id, url_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the anime reviews dataset created earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>username</th>\n",
       "      <th>rating</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>51535</td>\n",
       "      <td>NineTnk</td>\n",
       "      <td>10</td>\n",
       "      <td>This is what peak storytelling meet peak adapt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51535</td>\n",
       "      <td>I_am_free_950</td>\n",
       "      <td>10</td>\n",
       "      <td>Hajime Isayama, I have no doubt that he is a p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>51535</td>\n",
       "      <td>Doofenheimer</td>\n",
       "      <td>10</td>\n",
       "      <td>The pinnacle of shonen has returned. Attack On...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>51535</td>\n",
       "      <td>AnimeOdyssey</td>\n",
       "      <td>2</td>\n",
       "      <td>As a fan of the anime medium, it is with great...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51535</td>\n",
       "      <td>Mecopterraaa</td>\n",
       "      <td>10</td>\n",
       "      <td>It was a masterpiece, the animation quality, t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   anime_id       username  rating  \\\n",
       "0     51535        NineTnk      10   \n",
       "1     51535  I_am_free_950      10   \n",
       "2     51535   Doofenheimer      10   \n",
       "3     51535   AnimeOdyssey       2   \n",
       "4     51535   Mecopterraaa      10   \n",
       "\n",
       "                                              review  \n",
       "0  This is what peak storytelling meet peak adapt...  \n",
       "1  Hajime Isayama, I have no doubt that he is a p...  \n",
       "2  The pinnacle of shonen has returned. Attack On...  \n",
       "3  As a fan of the anime medium, it is with great...  \n",
       "4  It was a masterpiece, the animation quality, t...  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filepath = \"./Dataset/\" + ANIME_REVIEWS_FILENAME\n",
    "anime_info_df = pd.read_csv(filepath, encoding='utf-16', thousands=\",\")\n",
    "anime_info_df.head(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "006ceec57082682d3b909e056014cfb3f67146c2ee1293d561029ad71ca64256"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
